---
title: "Term Project Code"
author: "Lianne Sheppard for ENVH 556"
date: "Winter 2021; Updated `r format(Sys.time(), '%d %B, %Y')`"
output: 
    html_document:
        df_print: "paged"
        fig_caption: yes
        toc: true
        toc_depth: 3
        number_sections: true
---

```{r setup, include=FALSE}
#-----setup-----

# set knitr options
knitr::opts_chunk$set(echo = TRUE)

# clear work space of all objects and unload all extra (non-base) packages
rm(list = ls(all = TRUE))
if (!is.null(sessionInfo()$otherPkgs)) {
    res <- suppressWarnings(
            lapply(paste('package:', names(sessionInfo()$otherPkgs), sep=""),
                   detach, character.only=TRUE, unload=TRUE, force=TRUE)) 
    rm(res)
}

```

```{r load.libraries.pacman, echo=FALSE, include=FALSE, eval=TRUE}
#-----load libraries pacman-----

# Load pacman into memory, installing as needed
my_repo <- 'http://cran.r-project.org'
if (!require("pacman")) {install.packages("pacman", repos = my_repo)}

# Load the other packages, installing as needed.
pacman::p_load(knitr, dplyr, tidyr, forcats, stringr, ggplot2, Hmisc)

```

```{r directory.organization.and.read.data, echo=FALSE, warning=FALSE}
#-----directory organization and read data-----

# specify working directory
project_path <- getwd()

# create "Datasets" directory if one does not already exist    
dir.create(file.path(project_path,"Datasets"), showWarnings=FALSE, recursive = TRUE)

# specify data path
data_path <- file.path(project_path,"Datasets")

# specify files to read (their names will be used for variable assignment)
file_names <- c(cohist = "cohist.rds", 
                REC = "RECpersonal.rds", 
                jem = "jem.rds"
                )

# read in files programmatically to a temporary object
temp <- lapply(file_names, function(x){

    # build file path
    file_path <- file.path(data_path, x)
    
    # Download the file if it is not already present
    if (!file.exists(file_path)) {
        url <- paste("https://staff.washington.edu/high/envh556/Datasets", 
                     x, sep = '/')
        download.file(url = url, destfile = file_path)
    }
    
    # Read in data, convert to tibble, outputting warning if file cannot be found
    if (file.exists(file_path)) {
        readRDS(file_path) %>% as_tibble()
    } else warning(paste("Can't find", file_name, "!"))

}) %>% 
    
    # name list elements
    setNames(names(file_names)) %>% 
    
    # extract list elements into the global environment
    list2env(globalenv())

# remove temporary variables
rm(temp, file_names, object_names, data_path)

```


# Introduction and Context

This is the companion R Markdown file to the JEM procedure overview file:
*JEM_syntax*.  These files describe the general steps for generating a
Job Exposure Matrix (JEM) for REC from the DEMS datasets.  It also addresses
dataset features you need to be aware of for your project.  Other important
aspects of the project are not described here.

There are basically 4 steps to creating the JEM for REC from the DEMS data: 

    a) Predict REC from a model by mine and job,   
    
    b) Predict historical CO from a model by mine and year,   
    
    c) Combine the two sets of predictions into a JEM for each mine, job and
       year, and
    
    d) Calculate the predicted historical REC estimates.  

The syntax that we provide for you in this R Markdown file is supposed to be
generic â€“ that is, it will work, but the models we have provided are not
necessarily the best ones to use.  For instance, in the sample code in Section
3, we have fit simple models for all mines combined, and we have also
demonstrated the methods you would need to predict from these models.  Because
there were some complicated aspects of handling the period factor variables, in
Section 4 we repeated parts of this work using period instead of year as the
time variable.   You need to explore and determine the best models, and
interpret the results.

# Data overview

## Basic observations about the datasets

Let's get a quick summary of each dataset to begin to grapple with some of the
data features we will need to address in this project.

```{r show.datasets}
#-----show datasets-----

# show each of the dataset tibbles
REC
cohist
jem

```

Observations about the datasets: (also demonstrates inline reporting from R)

* **Numbers of observations**:  The number of rows in each dataset:
    - `REC`:      `r nrow(REC)`
    - `cohist`:   `r nrow(cohist)`
    - `jem`:      `r nrow(jem)`

* **Facility**:  All datasets have one or two variables to identify facility.
Two of them (`cohist` and `REC`) have two variables while `jem` has only one.
Also the lone facility variable in `jem`, *facilityno* is a factor variable with
the combination of the facility letter and number.  This is also true in `REC`.
However, this variable in `cohist` is only a number.

* **Time**:  REC was only collected during the NIOSH survey and so doesn't have
a time period.  `cohist` has whole years and a variable *period* which is an
integer coded from 2-8.  `jem` has both *year* and *period*.  Coding is
identical for year but the *period* variable is a factor rather than
an integer.  To learn how `cohist` and `jem` definitions of period align, we
need to do a merge and compare them.  See below.

* **Job**:  `jem` has a single variable *job* which is coded the same as the
variable *job* in `REC`.  `REC` has two additional job variables:  *mdj*, the
concatenation of mine (as a number), department, and job, and *job98* which is
not identical to *job* and is an integer variable, a slightly recoded version of
*mdj*.

## Some preliminary data management

Here is some code to create a factor variable for facility in `cohist` that
aligns with the similar factor variable in the other two datasets.  We also
investigate the period variable in `cohist` and `jem` and then create a new
variable *periodfac* which is a factor variable coded the same across datasets.
(In your analyses be careful to take note of which datasets have which
information and how you will approach this.)

```{r preliminary data management}
#-----preliminary data management-----

# get the facilityno factor levels in the REC dataset for fixing cohist
fn_levels <- levels(REC$facilityno)

# now create a factor version of facility in cohist
cohist <- cohist %>%
    mutate(facilitychar = str_c(facilityid,facilityno),
           facilityfac = factor(facilitychar, levels = fn_levels) ) 

# figure out the period variables
# period in cohist
with(cohist, table(year, period))
# observe only 4 observations in period 2 (in 1972), a fair number in periods
# 3-7, and only 15 in period 8
# 
# period in jem
with(jem, table(year, period))

# observe 
#   1. 120 observations per year-period combo
#   2. year starts in 1947, ends in 2003
#   3. periods and their two versions of coding are: 
#       cohist:  jem:    Definitions:  i.e.,
#  period level  period  (all years in the time period)
#  ============  ======  ==========================
#           1 -- 55      (1947-1970)
#           2 -- 71-72   (1971-1975)
#           3 -- 76-79   (1976-1979)
#           4 -- 80-84   (1980-1984)
#           5 -- 85-89   (1985-1989)
#           6 -- 90-94   (1990-1994)
#           7 -- 95-99   (1995-1999)
#           8 -- 2001    (2000-2003)

# Now check the jem vs cohist data and see who they align at the year level
# get the first period of each year in cohist
cohist_uniq <- cohist %>%
    group_by(year) %>%
    summarise(period_uniq = first(period), 
              .groups = "drop")

# join jem and cohist_uniq as an inner join (only keep those that match) and
# then make a table to learn the number of years they have in common by period
testjem <- inner_join(jem, cohist_uniq, by = "year" )

# observe how the periods line up in jem and cohist; note that there are no
# cohist data for the earliest time period available in the jem
with(testjem,table(period, period_uniq))

# fix the period coding to be consistent across datasets:
# 1. make period a factor in cohist
# 2. recode in jem to create periodfac variable that aligns across datasets
cohist <- cohist %>% 
    mutate(period = factor(period), 
           periodfac = fct_recode(period, 
                                  "1971-1975" = "2",
                                  "1976-1979" = "3",
                                  "1980-1984" = "4",
                                  "1985-1989" = "5",
                                  "1990-1994" = "6",
                                  "1995-1999" = "7",
                                  "2000-2003" = "8") )

jem <- jem %>% 
    mutate(periodfac = fct_recode(period, 
                                  "1947-1970" = "55",
                                  "1971-1975" = "71-72",
                                  "1976-1979" = "76-79",
                                  "1980-1984" = "80-84",
                                  "1985-1989" = "85-89",
                                  "1990-1994" = "90-94",
                                  "1995-1999" = "95-99",
                                  "2000-2003" = "2001") )

```

# Analysis Steps when **Year** is the Time Variable

## REC Models:  

**Predict REC from observations and create a new dataset with an estimated AM
for each mine and job**

###	Create lnrec = ln(ecdata) 

```{r update.REC}
#-----update REC-----
 
# create lnrec
REC <- mutate(REC, lnrec = log(ecdata))

```

###	Estimate an AM for each mine and job combination

**Use one of the approaches we learned in class**

We show regression and the MLE estimate of the arithmetic mean (AM) using a
single very simple model with all facilities together.  Your job is to decide
how you want to approach this analysis (e.g how will you estimate the AM for each facility-job combination and why?) using
the tools we have learned over the quarter.  Here are some considerations (some
apply to the CO data also):

* Regression is just one way to do this. Even if you use regression, what kind of model will you use?  Should you collapse any jobs into groups? 
* How you approach the modeling will affect whether you can predict for all job
and facility combinations.  Think about what predictions you believe are
supported scientifically.
* We have not addressed here how to handle facility J. If you are going to try
to predict at this facility, how will you approach it and why?  (Hint:  You can
consult the DEMS papers for ideas.)

```{r REC.regression.for.prediction}
#-----REC regression for prediction-----

# first create job as a factor variable and set the reference level to be job 410
# 410 is a common job and thus a useful reference category
# relevel easily moves the specified factor to be first or the reference in
# regression
REC <- REC %>% 
    mutate(jobfac = factor(job), 
           jobfac = fct_relevel(jobfac, ref = "410") )

# regression
rec_fit <- lm(lnrec ~ facilityno + jobfac, data = REC)

# create a new dataset that has one observation per job and facility
# (Make sure you include all covariates in your regression model)

# Choose one of the following; comment out the other

# 1. The following only picks out the distinct job-facility combinations that
# exist in the dataset, n = 50
# newdat <- REC %>%
#    select(facilityno, facilityid, job, jobfac) %>%
#    distinct()

# 2. Here is the alternative to get all possible values of the facilityno and
# job combinations, n = 105
# Note:  still need to address the missing facility J 
newdat <- with(REC, expand.grid(facilityno = unique(facilityno), 
                                jobfac = unique(jobfac)) ) %>% 
    as_tibble()

# prediction over all facilityno job combinations
rec_pred <- predict(rec_fit, newdat, se.fit = TRUE)

# add variables to newdat, including the MLE-based AM
newdat <- newdat %>% 
    mutate(lnrec_p = rec_pred$fit, 
           lnrec_pvar = rec_pred$se.fit^2 + rec_pred$residual.scale^2, 
           rec_AM = exp(lnrec_p + lnrec_pvar/2) )

# for getting the above variance of a new obs from predict(), see e.g. https://stackoverflow.com/questions/38109501/how-does-predict-lm-compute-confidence-interval-and-prediction-interval/38110406#38110406
 
# use this code version for the first newdat definition
#REC_new <- newdat %>% 
#    select(facilityno, job, jobfac, rec_AM)

# use this code version for the second newdat definition
REC_new <- newdat %>% 
    mutate(job = as.integer(as.character(jobfac))) %>%
    select(facilityno, job, jobfac, rec_AM)

```


###	Estimate of the AM for each mine and job combination

See above.  Combined with the regression and prediction chunk.

## CO models:  By year

**Model CO concentration from observations and create a new dataset with an estimated AM for each mine and *year*. **

###	Estimate an AM for each mine and job combination by time period (individual **years**).

Use one of the approaches we learned. 

We show regression and the MLE estimate of the arithmetic mean (AM) using a
single very simple model with all facilities together and year as a factor
variable.  Your job is to decide how you want to approach this using the tools
we have learned over the quarter.

```{r CO.regression.for.prediction}
#-----CO regression for prediction-----

# a basic regression
simple_fit <- lm(lnco ~ facilityfac + as.factor(year), data = cohist)

# prediction over all facility-year combinations
# Choose one of the following; comment out or delete the other
#
# The following only picks out the distinct year-facility combinations that
# exist in the dataset, n = 159
#newdat <- cohist %>% 
#    select(facilityfac, facilityno, facilityid, year, period) %>%
#    distinct()

# Here is the alternative to get all possible values of the facility and times
# combinations, n = 208
newdat <- with(cohist, expand.grid(facilityfac = unique(facilityfac), 
                                   year = unique(year))) %>% 
    as_tibble()

# prediction over all facilityfac and year combinations
new_co <- predict(simple_fit, newdat, se.fit = TRUE)

# add predictions to newdat tibble, calculate stats of interest
newdat <- newdat %>% 
    mutate(lnco_p = new_co$fit, 
           lnco_pvar = new_co$se.fit^2 + new_co$residual.scale^2, 
           co_AM = exp(lnco_p + lnco_pvar/2) )

# create dataset to merge, addressing facilityno isn't a factor variable coded
# the same way as in the other datasets

# Use this version for the first newdat definition:
#CO_new <- newdat %>%
#    select(facilityno, facilityfac, year, period, co_AM)

# Use this version for the second newdat definition
# Note it drops period
CO_new <- newdat %>%
    mutate(facilityno = as.character(facilityfac)) %>%
    select(facilityno, facilityfac, year, co_AM)

```
###	Produce an estimate of the AM for each mine and time combination (**year**)

See above.  Combined with the regression and prediction chunk.

## Put predictions into the JEM by merging dataframes

We have created the JEM for you.  It has a record for each combination of job,
year (thus also period) and facilityno.  This step requires that you merge the
data from `REC` and from `cohist` into the JEM.  In `tidyverse`, merging is call
joining.  The syntax below is from `tidyverse`, specifically from the `dplyr`
package.  To learn more about joins, see *R for Data Science*
[R4DS](https://r4ds.had.co.nz/index.html), specifically the chapter on
relational data, [Chapter 13](https://r4ds.had.co.nz/relational-data.html).

An important part of joining datasets is making sure the results you get from
the join are as you expect and are correctly joined.  Make sure you understand
the datasets you are joining, how they relate to each other, and the keys (or
variables) you will use to merge them with.  Keys connect the two datasets or
tables.  They can be comprised of multiple variables.  For our data, we
ultimately want data merged by time (*year* or *period*), *job*, and facility
(*facilityid* or *facilityno*).  Thus these will make up our key variables.
Note the `REC` dataset only has facility and job, while the `cohist` dataset
only has facility and time.  So the keys in each of those joins will be
different.

### Merge REC into the JEM by facility and job

We will use a left join and join REC into the JEM.  The left join includes all rows in the first object x (jem here), and will repeat the value in the second object y (REC_new here) as needed.  Since the JEM has multiple  years per facility and job, the values of REC_new will be repeated every year.

In principle we want to preserve all rows of the JEM, although if the REC data
don't have values we don't want bogus data to be inserted.  We'd prefer to have
those be NAs.  (An alternative would be to drop row of the JEM that don't match
REC.  However, it is probably easier to keep track of our objectives by keeping
all JEM rows and then addressing later those that don't have data in them.)

```{r leftjoin.JEM.with.REC}
#-----leftjoin JEM with REC-----

JEM_REC <- left_join(jem, REC_new, by = c("facilityno", "job"))

```

Note:  it is critical that you develop habits to make sure the data you get from
a procedure are what you expect.  This is particularly important after doing a
join.  Add code to the next chunk to check whether you did the matching in the
merge correctly.  You should at least verify the sample sizes indicate whether
you have the data you expect.  Find out whether there are any records without a
match.  Does it make sense to you that these records haven't matched?

```{r check.the.join.of.JEM.with.REC}
#-----check the join of JEM with REC-----

# This has 855 observations per facility (n = 8 facilities) and 57 per job (n=15
# jobs).

JEM_REC %>% group_by(facilityno, job) %>%
    summarise( N = n(),
            AM_missing = sum(is.na(rec_AM) ),
            mean_AM = mean(rec_AM),
            sd_AM = sd(rec_AM),
            zero_AM = sum(rec_AM == 0),
            .groups = "drop")

# It would be good to spot check some AM values or otherwise verify that the join worked properly.  There is a value for every job and facility except facility J.  Does this make sense scientifically and given the way we generated the data?

```


###	Merge CO into the JEM by facility and time (**year**)

```{r leftjoin.JEM.with.CO}
#-----leftjoin JEM with CO-----

# now join the JEM_REC dataframe with CO_new to creat the new JEM
JEM_new <- left_join(JEM_REC, CO_new, 
                     by = c("facilityno", "year") )

```


Make sure to verify you did the merge correctly.  Fill in some code to check the JEM_new object until you are reassured that the merge worked as you expect and intend.

```{r check.the.join.of.JEM.with.CO}
#-----check the join of JEM with CO------

# ADD this

```

## Compute REC for each observation within JEM dataset 

Use a version of the formula in DEMS IV to estimate the REC for each observation
in the JEM dataset
    - Formula:  `rec_mjy = (co_AM / baselineco) * rec_AM`, or in  $\LaTeX$ mode:  
    $$  rec_{mjy} = \frac{co_{AM}}{baselineco} * rec_{AM} $$  
    - Note:  Not all combinations of mine, job, and year should have AM
    estimates, therefore you should have missing predictions that you will need
    to drop or impute using assumptions and other information in your dataset.
    In conjuction with this step, make sure you are only missing predictions
    where you expect them to be missing.


```{r predicted.REC.in.JEM}
#-----predicted REC in JEM-----

# estimate the CO ratio and the REC concentration
JEM <- JEM_new %>%
    mutate(co_ratio = co_AM / baselineco,
           rec_mjy =  co_ratio * rec_AM
           )

# show JEM
JEM

```

Some summaries of the final JEM:

```{r describe.JEM}
#-----describe JEM-----

describe(JEM)

```

# Analysis Steps when **Period** is the Time Variable

## REC Models:  

**Predict REC from observations and create a new dataset with an estimated AM
for each mine and job**

No changes needed

## CO models:  By period

**Model CO concentration from observations and create a new dataset with an estimated AM for each mine and *period*. **

###	Estimate an AM for each mine and job combination by time **period**. 

Use one of the approaches we learned.  Time periods are categories here.

Repeat example regression and the MLE estimate of the arithmetic mean (AM) using
a single very simple model with all facilities together.  This time with period
as the time variable.

```{r CO.regression.for.prediction.on.period}
#-----CO regression for prediction on period-----

# a basic regression
simple_fit <- lm(lnco ~ facilityfac + periodfac, data = cohist)

# prediction over all facilityno period combinations
# Use expand.grid to get all possible values of the facilityno and period
# combinations, n = ADD
newdat <- with(cohist, expand.grid(facilityfac = unique(facilityfac), 
                                   periodfac = unique(periodfac))) %>% 
    as_tibble()

# prediction over all facilityno year combinations
new_co <- predict(simple_fit, newdat, se.fit=TRUE)

# add predictions to newdat
newdat <- newdat %>% 
    mutate(lnco_p = new_co$fit, 
           lnco_pvar = new_co$se.fit^2 + new_co$residual.scale^2, 
           co_AM = exp(lnco_p + lnco_pvar/2) )

# create dataset to merge, addressing facilityno isn't a factor variable coded
# like in the other datasets AND that period is coded differently in JEM

# Use this version for the expand.grid newdat definition
# Note it drops year
CO_new <- newdat %>%
    mutate(facilityno = as.character(facilityfac)) %>%
    select(facilityno, facilityfac, periodfac, co_AM)

```

###	Produce an estimate of the AM for each mine and time combination

See above.  Combined with the regression and prediction chunk.

## Put predictions into the JEM



### Merge REC into the JEM by facility and job

Completed previously.  Result is in `JEM_new`.


###	Merge CO into the JEM by facility and time **period**

```{r leftjoin.JEM.with.CO.by.period}
#-----leftjoin JEM with CO by period-----

JEM_new <- left_join(JEM_REC, CO_new, 
        by = c("facilityno", "periodfac"))

```


Make sure to verify you did the merge correctly.  

```{r check.the.join.of.JEM.with.CO.by.period}
#-----check the join of JEM with CO by period-----

# ADD your own code to check this

```

## Compute REC for each observation within JEM dataset 
Repeat, by period this time.  It is worthwhile to think about whether you can
sensibly fill in data for missing periods and how you will do this.

```{r predicted.REC.in.JEM.by.period}
#-----predicted REC in JEM by period-----

JEM <- JEM_new %>%
    mutate(co_ratio = co_AM /baselineco,
           rec_mjy =  co_ratio * rec_AM
           )

# show JEM
JEM
```

Some summaries of the final JEM:

```{r describe.JEM.by.period}
# ----describe JEM by period-----

describe(JEM)

```


# Further comments and suggestions

In this project code file we have worked through the entire process of computing a JEM using two different ways of handling time in the CO data: using individual years vs time periods.  Note that the analyses in this file are for demonstration purposes only and **do not necessarily represent the best scientific choices for each modeling step**.  The purpose of this file is to give you the technical support to complete coding of the Term Project without also making scientific choices for you.

As you work through the analysis of your project, think about how you can check your results and determine how sensible you think they are.  Below are some examples that we considered:

* Are there meaningful differences in the `co_ratio` estimates between using year vs. time period?  

    - In this example we used fairly simple-minded models, so there could be good reasons why there are differences.  However, differences could suggest a problem with the data analysis that needs to be corrected before the results are reported.  It is good to generally question your data and look for errors.

    - In this sample code we estimated CO with 2 different "simple_fit" models (one
by year, one by period) and merged dataframes, creating the `JEM` object. The
second time we did that we reassigned all the same variables, overwriting them,
including the final `JEM`. One alternative would be to assign each JEM object to
new names, e.g., `JEM_year` and `JEM_period`, so we retain both objects to allow
comparisons. Also if we name variables by the approach to creating them, e.g.,
`co_AM_year` and `co_AM_period` (and similar for `co_ratio` and `rec_mjy`), then
we could then merge the JEM objects together into one and make direct
comparisons of results.

* It would be worthwhile to look at how the CO estimates compare with the
numbers given in Table 3 of DEMS IV.  The following chunk accomplishes this comparison.  A follow-up to this analysis would be to think about what this comparison tells you and consider whether you need to make any changes to your approach based on it.


```{r compare.to.DEMS.IV}
#-----compare to DEMS IV-----

dems_IV <- tibble(facilityno = c("B16", "D21", "E13", "H6", "I8", "J18"), 
                  CO_1976_1977 = c(5.15, 7.98, 10.60, 3.90, 4.85, 4.36))

est_dems_IV <- JEM %>% 
    filter(periodfac == "1976-1979") %>% 
    group_by(facilityno) %>% 
    summarise(mean_CO = mean(co_AM), 
              .groups = "drop")

# these can be merged to inspect their comparability:
right_join(dems_IV, est_dems_IV, by = "facilityno")

```



# Appendix

## Session information

```{r session.info}
#-----session information-----

# print R session information
sessionInfo()

```

## Embedded code

```{r code.appendix, ref.label = knitr::all_labels(), echo = TRUE, eval = FALSE, , include=TRUE}
#-----code appendix-----
```

## Functions defined 

```{r functions, eval = TRUE}
#-----functions-----

# Show the names of all functions defined in the .Rmd
# (e.g. loaded in the environment)
lsf.str()

# Show the definitions of all functions loaded into the current environment  
lapply(c(lsf.str()), getAnywhere)

```

